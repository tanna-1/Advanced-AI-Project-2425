{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858358ca",
   "metadata": {},
   "source": [
    "# Text Prediction Model\n",
    "\n",
    "This notebook provides an interactive interface for working with the text prediction model, which is designed to predict and generate text one character at a time. The model learns to predict the next character in a sequence and can be used to generate new text content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be38df7e",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "from advanced_ai_project.model import MLPCheckpoint\n",
    "from advanced_ai_project.hyperparameters import load_hyperparameters, optimize_hyperparameters\n",
    "from advanced_ai_project.text_prediction.train import train as train_text_prediction\n",
    "from advanced_ai_project.text_prediction.evaluate import evaluate as evaluate_text_prediction, print_tokens, META_TRAINING_EPOCHS\n",
    "from advanced_ai_project.text_prediction.dataset import ByteFileDataset, StringDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b0fc3",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set up the necessary parameters for the text prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "dataset_path = \"../data/text.txt\" # Path to the text dataset\n",
    "checkpoint_path = \"../data/text_prediction_checkpoint.pt\"  # Path to save or load the model checkpoint\n",
    "study_path = \"../data/text_prediction_study.db\"  # Path to the database for storing/loading hyperparameters\n",
    "\n",
    "# Evaluation parameters\n",
    "generation_length = 100  # Number of characters to generate\n",
    "temperature = 0.8  # Controls the randomness of the generated text (higher = more random)\n",
    "top_k = 5  # Number of top predictions to sample from\n",
    "\n",
    "# Training parameters\n",
    "training_batch_size = 128\n",
    "training_num_epochs = 5\n",
    "training_length_cutoff = None\n",
    "\n",
    "# Optimization parameters\n",
    "opt_trials = 100\n",
    "opt_batch_size = 128\n",
    "opt_num_epochs = 2\n",
    "opt_length_cutoff = 1000\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(study_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(dataset_path), exist_ok=True)\n",
    "ckpt = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e019b",
   "metadata": {},
   "source": [
    "## 3. Load Text Dataset\n",
    "\n",
    "Load the text data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ByteFileDataset(dataset_path, length_cutoff=training_length_cutoff)\n",
    "opt_dataset = ByteFileDataset(dataset_path, length_cutoff=opt_length_cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc0066d",
   "metadata": {},
   "source": [
    "## 4. Optimize Hyperparameters\n",
    "\n",
    "This cell optimizes the hyperparameters for the text prediction model using Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(checkpoint_path).exists():\n",
    "    print(f\"Checkpoint file exists at {checkpoint_path}. Hyperparameters will not be optimized.\")\n",
    "else:\n",
    "    optimize_hyperparameters(\n",
    "        study_path,\n",
    "        opt_dataset,\n",
    "        n_trials=opt_trials,\n",
    "        num_epochs=opt_num_epochs,\n",
    "        batch_size=opt_batch_size,\n",
    "        train_model=\"text_prediction\",\n",
    "    )\n",
    "    print(f\"Hyperparameter optimization completed. Results stored in {study_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bab716",
   "metadata": {},
   "source": [
    "## 5. Train Text Prediction Model\n",
    "\n",
    "This cell trains the text prediction model using the optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d957c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or create checkpoint\n",
    "try:\n",
    "    ckpt = MLPCheckpoint.load(checkpoint_path)\n",
    "    print(\"Loaded existing checkpoint.\")\n",
    "except:\n",
    "    try:\n",
    "        ckpt = MLPCheckpoint.new_from_hyperparams(load_hyperparameters(study_path))\n",
    "        print(\"Created new checkpoint from hyperparameters.\")\n",
    "    except:\n",
    "        print(\n",
    "            f\"Neither checkpoint or the hyperparameter DB exists. Please run hyperparameter optimization first.\"\n",
    "        )\n",
    "        raise\n",
    "\n",
    "# Train the model\n",
    "print(\"Training text prediction model...\")\n",
    "ckpt.model.train()\n",
    "avg_loss = train_text_prediction(\n",
    "    ckpt,\n",
    "    dataset=dataset,\n",
    "    num_epochs=training_num_epochs,\n",
    "    batch_size=training_batch_size,\n",
    ")\n",
    "print(f\"Training complete with an average loss of {avg_loss}\")\n",
    "\n",
    "# Save the model\n",
    "ckpt.save(checkpoint_path)\n",
    "print(f\"Model saved to {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c63ee4c",
   "metadata": {},
   "source": [
    "## 6. Evaluate Text Prediction Model\n",
    "\n",
    "This cell generates text using the trained text prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38706ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ckpt is None:\n",
    "    ckpt = MLPCheckpoint.load(checkpoint_path)\n",
    "\n",
    "# You can change the start index to generate text from a different position in the dataset\n",
    "start_idx = 0\n",
    "print(\"Generating text with the model...\")\n",
    "\n",
    "print(\"Generated text:\\n\")\n",
    "tokens = evaluate_text_prediction(\n",
    "    ckpt,\n",
    "    idx=start_idx,\n",
    "    length=generation_length,\n",
    "    temperature=temperature,\n",
    "    top_k=top_k,\n",
    ")\n",
    "print_tokens(tokens)\n",
    "print(\"\\n\\nText generation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cf83df",
   "metadata": {},
   "source": [
    "## 7. Autocomplete Text\n",
    "\n",
    "This cell uses the trained model to autocomplete text from a given prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ckpt is None:\n",
    "    ckpt = MLPCheckpoint.load(checkpoint_path)\n",
    "\n",
    "# Set your prompt text here\n",
    "prompt = \"Hello, this is a test. I want to\"\n",
    "\n",
    "print(\"Autocompleting text from prompt...\")\n",
    "start_index = ckpt.last_seen_index + 1\n",
    "\n",
    "print(\"Training on the prompt...\")\n",
    "ckpt.model.train()\n",
    "avg_loss = train_text_prediction(\n",
    "    ckpt,\n",
    "    StringDataset(prompt, start_index=start_index),\n",
    "    num_epochs=META_TRAINING_EPOCHS,\n",
    "    batch_size=1,\n",
    ")\n",
    "print(f\"Prompt training complete with an average loss of {avg_loss}\")\n",
    "\n",
    "print(\"\\nPrompt:\")\n",
    "print(prompt)\n",
    "print(\"\\nAutocompleted text:\")\n",
    "tokens = evaluate_text_prediction(\n",
    "    ckpt,\n",
    "    start_index + len(prompt),\n",
    "    generation_length,\n",
    "    temperature=temperature,\n",
    "    top_k=top_k,\n",
    ")\n",
    "print_tokens(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b0dc9",
   "metadata": {},
   "source": [
    "## 8. Model Summary\n",
    "\n",
    "Display a summary of the text prediction model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ckpt is None:\n",
    "    ckpt = MLPCheckpoint.load(checkpoint_path)\n",
    "\n",
    "print(summary(\n",
    "    ckpt.model,\n",
    "    input_data=torch.zeros(\n",
    "        (1, 64), dtype=torch.int64, device=ckpt.model.device\n",
    "    ),\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
